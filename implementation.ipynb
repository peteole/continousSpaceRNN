{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 11:42:12.461779: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-30 11:42:12.694433: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-30 11:42:13.325815: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-30 11:42:13.325858: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-30 11:42:13.325863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/olep/.local/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n",
      "/home/olep/.local/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "import tensorflow_graphics as tfg\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "from image_interpolation import ImageInterpolator, ImageSectionRNNCell, generate_2d_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeated input:  KerasTensor(type_spec=TensorSpec(shape=(None, 20, 28, 28, 3), dtype=tf.float32, name=None), name='tf.repeat_3/Repeat/Reshape_1:0', description=\"created by layer 'tf.repeat_3'\")\n",
      "state_t:  (ListWrapper([<tf.Tensor 'module_wrapper_6/rnn_3/zeros:0' shape=(None, 32) dtype=float32>, <tf.Tensor 'module_wrapper_6/rnn_3/zeros_1:0' shape=(None, 32) dtype=float32>]), <tf.Tensor 'module_wrapper_6/rnn_3/zeros_2:0' shape=(None, 3) dtype=float32>)\n",
      "image:  Tensor(\"module_wrapper_6/rnn_3/strided_slice_2:0\", shape=(None, 28, 28, 3), dtype=float32)\n",
      "starts Tensor(\"module_wrapper_6/rnn_3/image_section_rnn_cell_3/image_interpolator_3/strided_slice:0\", shape=(None, 2), dtype=float32)\n",
      "stops: Tensor(\"module_wrapper_6/rnn_3/image_section_rnn_cell_3/image_interpolator_3/add:0\", shape=(None, 2), dtype=float32)\n",
      "queries:  Tensor(\"module_wrapper_6/rnn_3/image_section_rnn_cell_3/image_interpolator_3/grid_generate/stack_2:0\", shape=(None, 8, 10, 2), dtype=float32)\n",
      "section_values:  Tensor(\"module_wrapper_6/rnn_3/image_section_rnn_cell_3/image_interpolator_3/batch_interp_regular_nd_grid/add_4:0\", shape=(None, 8, 10, 3), dtype=float32)\n",
      "processed_section_values:  Tensor(\"module_wrapper_6/rnn_3/image_section_rnn_cell_3/sequential_6/dense_12/Relu:0\", shape=(None, 32), dtype=float32)\n",
      "lstm_out:  Tensor(\"module_wrapper_6/rnn_3/image_section_rnn_cell_3/lstm_cell_3/mul_2:0\", shape=(None, 32), dtype=float32)\n",
      "next_section_command:  Tensor(\"module_wrapper_6/rnn_3/image_section_rnn_cell_3/sequential_7/dense_14/Sigmoid:0\", shape=(None, 3), dtype=float32)\n",
      "state_t:  (ListWrapper([<tf.Tensor 'module_wrapper_6/rnn_3/while/Placeholder_2:0' shape=(None, 32) dtype=float32>, <tf.Tensor 'module_wrapper_6/rnn_3/while/Placeholder_3:0' shape=(None, 32) dtype=float32>]), <tf.Tensor 'module_wrapper_6/rnn_3/while/Placeholder_4:0' shape=(None, 3) dtype=float32>)\n",
      "image:  Tensor(\"module_wrapper_6/rnn_3/while/TensorArrayV2Read/TensorListGetItem:0\", shape=(None, 28, 28, 3), dtype=float32)\n",
      "starts Tensor(\"module_wrapper_6/rnn_3/while/image_section_rnn_cell_3/image_interpolator_3/strided_slice:0\", shape=(None, 2), dtype=float32)\n",
      "stops: Tensor(\"module_wrapper_6/rnn_3/while/image_section_rnn_cell_3/image_interpolator_3/add:0\", shape=(None, 2), dtype=float32)\n",
      "queries:  Tensor(\"module_wrapper_6/rnn_3/while/image_section_rnn_cell_3/image_interpolator_3/grid_generate/stack_2:0\", shape=(None, 8, 10, 2), dtype=float32)\n",
      "section_values:  Tensor(\"module_wrapper_6/rnn_3/while/image_section_rnn_cell_3/image_interpolator_3/batch_interp_regular_nd_grid/add_4:0\", shape=(None, 8, 10, 3), dtype=float32)\n",
      "processed_section_values:  Tensor(\"module_wrapper_6/rnn_3/while/image_section_rnn_cell_3/sequential_6/dense_12/Relu:0\", shape=(None, 32), dtype=float32)\n",
      "lstm_out:  Tensor(\"module_wrapper_6/rnn_3/while/image_section_rnn_cell_3/lstm_cell_3/mul_2:0\", shape=(None, 32), dtype=float32)\n",
      "next_section_command:  Tensor(\"module_wrapper_6/rnn_3/while/image_section_rnn_cell_3/sequential_7/dense_14/Sigmoid:0\", shape=(None, 3), dtype=float32)\n",
      "state_t:  (ListWrapper([<tf.Tensor 'rnn_3/zeros:0' shape=(None, 32) dtype=float32>, <tf.Tensor 'rnn_3/zeros_1:0' shape=(None, 32) dtype=float32>]), <tf.Tensor 'rnn_3/zeros_2:0' shape=(None, 3) dtype=float32>)\n",
      "image:  Tensor(\"rnn_3/strided_slice_2:0\", shape=(None, 28, 28, 3), dtype=float32)\n",
      "starts Tensor(\"rnn_3/image_section_rnn_cell_3/image_interpolator_3/strided_slice:0\", shape=(None, 2), dtype=float32)\n",
      "stops: Tensor(\"rnn_3/image_section_rnn_cell_3/image_interpolator_3/add:0\", shape=(None, 2), dtype=float32)\n",
      "queries:  Tensor(\"rnn_3/image_section_rnn_cell_3/image_interpolator_3/grid_generate/stack_2:0\", shape=(None, 8, 10, 2), dtype=float32)\n",
      "section_values:  Tensor(\"rnn_3/image_section_rnn_cell_3/image_interpolator_3/batch_interp_regular_nd_grid/add_4:0\", shape=(None, 8, 10, 3), dtype=float32)\n",
      "processed_section_values:  Tensor(\"rnn_3/image_section_rnn_cell_3/sequential_6/dense_12/Relu:0\", shape=(None, 32), dtype=float32)\n",
      "lstm_out:  Tensor(\"rnn_3/image_section_rnn_cell_3/lstm_cell_3/mul_2:0\", shape=(None, 32), dtype=float32)\n",
      "next_section_command:  Tensor(\"rnn_3/image_section_rnn_cell_3/sequential_7/dense_14/Sigmoid:0\", shape=(None, 3), dtype=float32)\n",
      "state_t:  (ListWrapper([<tf.Tensor 'rnn_3/while/Placeholder_2:0' shape=(None, 32) dtype=float32>, <tf.Tensor 'rnn_3/while/Placeholder_3:0' shape=(None, 32) dtype=float32>]), <tf.Tensor 'rnn_3/while/Placeholder_4:0' shape=(None, 3) dtype=float32>)\n",
      "image:  Tensor(\"rnn_3/while/TensorArrayV2Read/TensorListGetItem:0\", shape=(None, 28, 28, 3), dtype=float32)\n",
      "starts Tensor(\"rnn_3/while/image_section_rnn_cell_3/image_interpolator_3/strided_slice:0\", shape=(None, 2), dtype=float32)\n",
      "stops: Tensor(\"rnn_3/while/image_section_rnn_cell_3/image_interpolator_3/add:0\", shape=(None, 2), dtype=float32)\n",
      "queries:  Tensor(\"rnn_3/while/image_section_rnn_cell_3/image_interpolator_3/grid_generate/stack_2:0\", shape=(None, 8, 10, 2), dtype=float32)\n",
      "section_values:  Tensor(\"rnn_3/while/image_section_rnn_cell_3/image_interpolator_3/batch_interp_regular_nd_grid/add_4:0\", shape=(None, 8, 10, 3), dtype=float32)\n",
      "processed_section_values:  Tensor(\"rnn_3/while/image_section_rnn_cell_3/sequential_6/dense_12/Relu:0\", shape=(None, 32), dtype=float32)\n",
      "lstm_out:  Tensor(\"rnn_3/while/image_section_rnn_cell_3/lstm_cell_3/mul_2:0\", shape=(None, 32), dtype=float32)\n",
      "next_section_command:  Tensor(\"rnn_3/while/image_section_rnn_cell_3/sequential_7/dense_14/Sigmoid:0\", shape=(None, 3), dtype=float32)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " tf.expand_dims_3 (TFOpLambd  (None, 1, 28, 28, 3)     0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " tf.repeat_3 (TFOpLambda)    (None, 20, 28, 28, 3)     0         \n",
      "                                                                 \n",
      " rnn_3 (RNN)                 (None, 32)                11979     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,309\n",
      "Trainable params: 12,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input=tf.keras.Input(shape=(28, 28,3))\n",
    "num_iterations=20\n",
    "repeated_input = tf.repeat(tf.expand_dims(input,1), repeats=num_iterations, axis=1)\n",
    "print(\"repeated input: \",repeated_input)\n",
    "classifier=keras.Sequential([\n",
    "    tf.keras.layers.RNN(ImageSectionRNNCell(grid_dim=(8, 10), units=32)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "output=classifier(repeated_input)\n",
    "model=tf.keras.Model(inputs=input, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test differentiable grid generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 11:22:11.191709: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-09-30 11:22:11.191793: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ideapad5pro): /proc/driver/nvidia/version does not exist\n",
      "2022-09-30 11:22:11.193544: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 16, 20, 2) dtype=float32 (created by layer 'tf.stack_2')>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts=tf.keras.Input(shape=(2,))\n",
    "ends=tf.keras.Input(shape=(2,))\n",
    "generate_2d_grid(starts, ends, (16, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test differentiable batched interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "images= tf.keras.Input(shape=(28, 28, 3), name='images')\n",
    "queries = tf.keras.Input(shape=(16, 16, 2), name='queries')\n",
    "interpolated = tfp.math.batch_interp_regular_nd_grid(\n",
    "            queries, [0.0, 0.0], [1.0, 1.0], images, axis=-3)\n",
    "print(interpolated.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test that linspace is differentiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name=None), name='tf.linspace_10/linspace/Slice:0', description=\"created by layer 'tf.linspace_10'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='tf.math.reduce_sum/Sum:0', description=\"created by layer 'tf.math.reduce_sum'\")\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.getitem_22), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[0., 1.],\n",
      "       [1., 2.]], dtype=float32)>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.getitem_23), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[0., 1.],\n",
      "       [1., 2.]], dtype=float32)>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "output: tf.Tensor([ 5. 15.], shape=(2,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[5. 5.]\n",
      " [5. 5.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inp=tf.keras.Input(shape=(2,))\n",
    "interval=tf.linspace(inp[:,0],inp[:,1],10)\n",
    "print(interval)\n",
    "s=tf.reduce_sum(interval,axis=0)\n",
    "print(s)\n",
    "model=tf.keras.Model(inputs=inp,outputs=s)\n",
    "#model.summary()\n",
    "values=tf.Variable([[0.0,1.0],[1.0,2.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(values)\n",
    "    out=model(values)\n",
    "    print('output:',out)\n",
    "    print(tape.gradient(out,values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.  1. ]\n",
      "  [1.  1.5]\n",
      "  [1.  2. ]]\n",
      "\n",
      " [[1.5 1. ]\n",
      "  [1.5 1.5]\n",
      "  [1.5 2. ]]\n",
      "\n",
      " [[2.  1. ]\n",
      "  [2.  1.5]\n",
      "  [2.  2. ]]], shape=(3, 3, 2), dtype=float32)\n",
      "(<tf.Tensor 'image_interpolator_1/add:0' shape=(None, 2) dtype=float32>,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"image_interpolator_1\" (type ImageInterpolator).\n\nin user code:\n\n    File \"/home/olep/Documents/software/continousSpaceRNN/image_interpolation.py\", line 33, in call  *\n        queries = generate(starts, stops, self.grid_dim)\n    File \"/home/olep/Documents/software/continousSpaceRNN/image_interpolation.py\", line 93, in generate  *\n        grid._grid(starts, stops, nums)\n    File \"/home/olep/.local/lib/python3.10/site-packages/tensorflow_graphics/geometry/representation/grid.py\", line 46, in _grid  *\n        params = [tf.unstack(tensor) for tensor in [starts, stops, nums]]\n\n    ValueError: Cannot infer argument `num` from shape (None, 2)\n\n\nCall arguments received by layer \"image_interpolator_1\" (type ImageInterpolator):\n  • image=tf.Tensor(shape=(None, 28, 28, 1), dtype=float32)\n  • section=tf.Tensor(shape=(None, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/olep/Documents/software/continousSpaceRNN/implementation.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/olep/Documents/software/continousSpaceRNN/implementation.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m interpolatorSectionInput\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/olep/Documents/software/continousSpaceRNN/implementation.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(tfg\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mrepresentation\u001b[39m.\u001b[39mgrid\u001b[39m.\u001b[39m_grid(starts\u001b[39m=\u001b[39m[\u001b[39m1.0\u001b[39m, \u001b[39m1.0\u001b[39m], stops\u001b[39m=\u001b[39m[\u001b[39m2.0\u001b[39m, \u001b[39m2.0\u001b[39m], nums\u001b[39m=\u001b[39m[\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m]))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/olep/Documents/software/continousSpaceRNN/implementation.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m interpolatorOutput\u001b[39m=\u001b[39mImageInterpolator(grid_dim\u001b[39m=\u001b[39;49m(\u001b[39m16\u001b[39;49m, \u001b[39m16\u001b[39;49m))(interpolatorImageInput,interpolatorSectionInput)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filezzqpsldm.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, image, section)\u001b[0m\n\u001b[1;32m     11\u001b[0m stops \u001b[39m=\u001b[39m (ag__\u001b[39m.\u001b[39mld(section)[:, :\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(section)[:, \u001b[39m2\u001b[39m:],)\n\u001b[1;32m     12\u001b[0m ag__\u001b[39m.\u001b[39mld(\u001b[39mprint\u001b[39m)(ag__\u001b[39m.\u001b[39mld(stops))\n\u001b[0;32m---> 13\u001b[0m queries \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(generate), (ag__\u001b[39m.\u001b[39;49mld(starts), ag__\u001b[39m.\u001b[39;49mld(stops), ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mgrid_dim), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     14\u001b[0m ag__\u001b[39m.\u001b[39mld(\u001b[39mprint\u001b[39m)(\u001b[39m'\u001b[39m\u001b[39mqueries: \u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mld(queries))\n\u001b[1;32m     15\u001b[0m interpolated \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tfp)\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mbatch_interp_regular_nd_grid, (ag__\u001b[39m.\u001b[39mld(queries), [\u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m], [\u001b[39m1.0\u001b[39m, \u001b[39m1.0\u001b[39m], ag__\u001b[39m.\u001b[39mld(image)), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m), fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file_3_193p_.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__generate\u001b[0;34m(starts, stops, nums, name)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mstack, ([ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(grid)\u001b[39m.\u001b[39m_grid, (ag__\u001b[39m.\u001b[39mld(starts), ag__\u001b[39m.\u001b[39mld(stops), ag__\u001b[39m.\u001b[39mld(nums)), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39mfor\u001b[39;00m (starts, stops) \u001b[39min\u001b[39;00m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mzip\u001b[39m), (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39munstack, (ag__\u001b[39m.\u001b[39mld(starts),), \u001b[39mNone\u001b[39;00m, fscope), ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39munstack, (ag__\u001b[39m.\u001b[39mld(stops),), \u001b[39mNone\u001b[39;00m, fscope)), \u001b[39mNone\u001b[39;00m, fscope)],), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file_3_193p_.py:12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mstack, ([ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(grid)\u001b[39m.\u001b[39;49m_grid, (ag__\u001b[39m.\u001b[39;49mld(starts), ag__\u001b[39m.\u001b[39;49mld(stops), ag__\u001b[39m.\u001b[39;49mld(nums)), \u001b[39mNone\u001b[39;49;00m, fscope) \u001b[39mfor\u001b[39;00m (starts, stops) \u001b[39min\u001b[39;00m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mzip\u001b[39m), (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39munstack, (ag__\u001b[39m.\u001b[39mld(starts),), \u001b[39mNone\u001b[39;00m, fscope), ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39munstack, (ag__\u001b[39m.\u001b[39mld(stops),), \u001b[39mNone\u001b[39;00m, fscope)), \u001b[39mNone\u001b[39;00m, fscope)],), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filed4y2b2ay.py:29\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___grid\u001b[0;34m(starts, stops, nums)\u001b[0m\n\u001b[1;32m     27\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     28\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 29\u001b[0m params \u001b[39m=\u001b[39m [ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39munstack, (ag__\u001b[39m.\u001b[39mld(tensor),), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m [ag__\u001b[39m.\u001b[39mld(starts), ag__\u001b[39m.\u001b[39mld(stops), ag__\u001b[39m.\u001b[39mld(nums)]]\n\u001b[1;32m     30\u001b[0m layout \u001b[39m=\u001b[39m [ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mlinspace, \u001b[39mtuple\u001b[39m(ag__\u001b[39m.\u001b[39mld(param)), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mzip\u001b[39m), \u001b[39mtuple\u001b[39m(ag__\u001b[39m.\u001b[39mld(params)), \u001b[39mNone\u001b[39;00m, fscope)]\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filed4y2b2ay.py:29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     28\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 29\u001b[0m params \u001b[39m=\u001b[39m [ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49munstack, (ag__\u001b[39m.\u001b[39;49mld(tensor),), \u001b[39mNone\u001b[39;49;00m, fscope) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m [ag__\u001b[39m.\u001b[39mld(starts), ag__\u001b[39m.\u001b[39mld(stops), ag__\u001b[39m.\u001b[39mld(nums)]]\n\u001b[1;32m     30\u001b[0m layout \u001b[39m=\u001b[39m [ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mlinspace, \u001b[39mtuple\u001b[39m(ag__\u001b[39m.\u001b[39mld(param)), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mzip\u001b[39m), \u001b[39mtuple\u001b[39m(ag__\u001b[39m.\u001b[39mld(params)), \u001b[39mNone\u001b[39;00m, fscope)]\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"image_interpolator_1\" (type ImageInterpolator).\n\nin user code:\n\n    File \"/home/olep/Documents/software/continousSpaceRNN/image_interpolation.py\", line 33, in call  *\n        queries = generate(starts, stops, self.grid_dim)\n    File \"/home/olep/Documents/software/continousSpaceRNN/image_interpolation.py\", line 93, in generate  *\n        grid._grid(starts, stops, nums)\n    File \"/home/olep/.local/lib/python3.10/site-packages/tensorflow_graphics/geometry/representation/grid.py\", line 46, in _grid  *\n        params = [tf.unstack(tensor) for tensor in [starts, stops, nums]]\n\n    ValueError: Cannot infer argument `num` from shape (None, 2)\n\n\nCall arguments received by layer \"image_interpolator_1\" (type ImageInterpolator):\n  • image=tf.Tensor(shape=(None, 28, 28, 1), dtype=float32)\n  • section=tf.Tensor(shape=(None, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "interpolatorImageInput=tf.keras.Input(shape=(28, 28, 1))\n",
    "interpolatorSectionInput=tf.keras.Input(shape=(3,))\n",
    "print(tfg.geometry.representation.grid._grid(starts=[1.0, 1.0], stops=[2.0, 2.0], nums=[3, 3]))\n",
    "interpolatorOutput=ImageInterpolator(grid_dim=(16, 16))(interpolatorImageInput,interpolatorSectionInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with the grid interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[4.0666666]]], shape=(1, 1, 1), dtype=float32)\n",
      "tf.Tensor([[[2.0000002 0.6666665]]], shape=(1, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "queries = tf.Variable([[[1.1, 1.3]]])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = tfp.math.batch_interp_regular_nd_grid(\n",
    "        queries, [0.0, 0.0], [3.0, 3.0], image, axis=-3)\n",
    "    print(z)\n",
    "print(tape.gradient(z, queries))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starts tf.Tensor([[0. 0.]], shape=(1, 2), dtype=float32)\n",
      "stops: tf.Tensor([[0.5 0.5]], shape=(1, 2), dtype=float32)\n",
      "queries:  tf.Tensor(\n",
      "[[[[0.   0.  ]\n",
      "   [0.   0.25]\n",
      "   [0.   0.5 ]]\n",
      "\n",
      "  [[0.25 0.  ]\n",
      "   [0.25 0.25]\n",
      "   [0.25 0.5 ]]\n",
      "\n",
      "  [[0.5  0.  ]\n",
      "   [0.5  0.25]\n",
      "   [0.5  0.5 ]]]], shape=(1, 3, 3, 2), dtype=float32)\n",
      "Interpolation:  tf.Tensor(\n",
      "[[[[1. ]\n",
      "   [1.5]\n",
      "   [2. ]]\n",
      "\n",
      "  [[2.5]\n",
      "   [3. ]\n",
      "   [3.5]]\n",
      "\n",
      "  [[4. ]\n",
      "   [4.5]\n",
      "   [5. ]]]], shape=(1, 3, 3, 1), dtype=float32)\n",
      "starts tf.Tensor([[0. 0.]], shape=(1, 2), dtype=float32)\n",
      "stops: tf.Tensor([[0.5 0.5]], shape=(1, 2), dtype=float32)\n",
      "queries:  tf.Tensor(\n",
      "[[[[0.   0.  ]\n",
      "   [0.   0.25]\n",
      "   [0.   0.5 ]]\n",
      "\n",
      "  [[0.25 0.  ]\n",
      "   [0.25 0.25]\n",
      "   [0.25 0.5 ]]\n",
      "\n",
      "  [[0.5  0.  ]\n",
      "   [0.5  0.25]\n",
      "   [0.5  0.5 ]]]], shape=(1, 3, 3, 2), dtype=float32)\n",
      "Interpolation:  tf.Tensor(\n",
      "[[[[1. ]\n",
      "   [1.5]\n",
      "   [2. ]]\n",
      "\n",
      "  [[2.5]\n",
      "   [3. ]\n",
      "   [3.5]]\n",
      "\n",
      "  [[4. ]\n",
      "   [4.5]\n",
      "   [5. ]]]], shape=(1, 3, 3, 1), dtype=float32)\n",
      "Sum:  tf.Tensor([[27.]], shape=(1, 1), dtype=float32)\n",
      "Gradient of sum w.r.t. section: tf.Tensor([[54. 18. 36.]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "image = tf.constant(\n",
    "    [[[[1.0], [2.0], [3.0]], [[4.0], [5.0], [6.0]], [[7.0], [8.0], [9.0]]]])\n",
    "interpolator = ImageInterpolator(grid_dim=(3, 3))\n",
    "print('Interpolation: ', interpolator(image, tf.constant([[0.0, 0.0, 0.5]])))\n",
    "section = tf.Variable([[0.0, 0.0, 0.5]])\n",
    "with tf.GradientTape() as tape:\n",
    "    interpolation = interpolator(image, section)\n",
    "    print('Interpolation: ', interpolation)\n",
    "    # Take sum alon the last two axes\n",
    "    s = tf.reduce_sum(interpolation, axis=1)\n",
    "    s2 = tf.reduce_sum(s, axis=1)\n",
    "    print(\"Sum: \", s2)\n",
    "print(\"Gradient of sum w.r.t. section:\", tape.gradient(s2, section))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
